{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c047e4cf-e4ab-4db4-a9c0-8cc15d4a331d",
   "metadata": {},
   "source": [
    "# 1. Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c18bf856-e0ea-4d15-9fdc-5f6314eb2131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2\n",
    "# import sys\n",
    "\n",
    "\n",
    "# # module level variables\n",
    "# MIN_CONTOUR_AREA = 40\n",
    "\n",
    "\n",
    "# RESIZED_IMAGE_WIDTH = 20\n",
    "# RESIZED_IMAGE_HEIGHT = 30\n",
    "\n",
    "# def main():\n",
    "#     imgTrainingNumbers = cv2.imread(\"training_chars.png\")            # read in training numbers image\n",
    "#     #imgTrainingNumbers = cv2.resize(imgTrainingNumbers, dsize = None, fx = 0.5, fy = 0.5)\n",
    "    \n",
    "#     imgGray = cv2.cvtColor(imgTrainingNumbers, cv2.COLOR_BGR2GRAY)          # get grayscale image\n",
    "#     imgBlurred = cv2.GaussianBlur(imgGray, (5,5), 0)                        # blur\n",
    "\n",
    "#                                                         # filter image from grayscale to black and white\n",
    "#     imgThresh = cv2.adaptiveThreshold(imgBlurred,                           # input image\n",
    "#                                       255,                                  # make pixels that pass the threshold full white\n",
    "#                                       cv2.ADAPTIVE_THRESH_GAUSSIAN_C,       # use gaussian rather than mean, seems to give better results\n",
    "#                                       cv2.THRESH_BINARY_INV,                # invert so foreground will be white, background will be black\n",
    "#                                       11,                                   # size of a pixel neighborhood used to calculate threshold value\n",
    "#                                       2)                                    # constant subtracted from the mean or weighted mean\n",
    "\n",
    "#     cv2.imshow(\"imgThresh\", imgThresh)      # show threshold image for reference\n",
    "\n",
    "#     imgThreshCopy = imgThresh.copy()        # make a copy of the thresh image, this in necessary b/c findContours modifies the image\n",
    "\n",
    "#     npaContours, hierarchy = cv2.findContours(imgThreshCopy,        # input image, make sure to use a copy since the function will modify this image in the course of finding contours\n",
    "#                                                  cv2.RETR_EXTERNAL,                 # retrieve the outermost contours only\n",
    "#                                                  cv2.CHAIN_APPROX_SIMPLE)           # compress horizontal, vertical, and diagonal segments and leave only their end points\n",
    "\n",
    "#                                 # declare empty numpy array, we will use this to write to file later\n",
    "#                                 # zero rows, enough cols to hold all image data\n",
    "#     npaFlattenedImages =  np.empty((0, RESIZED_IMAGE_WIDTH * RESIZED_IMAGE_HEIGHT))\n",
    "   \n",
    "\n",
    "#     intClassifications = []         # declare empty classifications list, this will be our list of how we are classifying our chars from user input, we will write to file at the end\n",
    "\n",
    "#                                     # possible chars we are interested in are digits 0 through 9, put these in list intValidChars\n",
    "#     intValidChars = [ord('0'), ord('1'), ord('2'), ord('3'), ord('4'), ord('5'), ord('6'), ord('7'), ord('8'), ord('9'),\n",
    "#                      ord('A'), ord('B'), ord('C'), ord('D'), ord('E'), ord('F'), ord('G'), ord('H'), ord('I'), ord('J'),\n",
    "#                      ord('K'), ord('L'), ord('M'), ord('N'), ord('O'), ord('P'), ord('Q'), ord('R'), ord('S'), ord('T'),\n",
    "#                      ord('U'), ord('V'), ord('W'), ord('X'), ord('Y'), ord('Z')] #Là mã ascii của mấy chữ này\n",
    "\n",
    "#     for npaContour in npaContours:                          # for each contour\n",
    "#         if cv2.contourArea(npaContour) > MIN_CONTOUR_AREA:          # if contour is big enough to consider\n",
    "#             [intX, intY, intW, intH] = cv2.boundingRect(npaContour)         # get and break out bounding rect\n",
    "\n",
    "#                                                 # draw rectangle around each contour as we ask user for input\n",
    "#             cv2.rectangle(imgTrainingNumbers,           # draw rectangle on original training image\n",
    "#                           (intX, intY),                 # upper left corner\n",
    "#                           (intX+intW,intY+intH),        # lower right corner\n",
    "#                           (0, 0, 255),                  # red\n",
    "#                           2)                            # thickness\n",
    "\n",
    "#             imgROI = imgThresh[intY:intY+intH, intX:intX+intW]                                  # crop char out of threshold image\n",
    "#             imgROIResized = cv2.resize(imgROI, (RESIZED_IMAGE_WIDTH, RESIZED_IMAGE_HEIGHT))     # resize image, this will be more consistent for recognition and storage\n",
    "\n",
    "#             cv2.imshow(\"imgROI\", imgROI)                    # show cropped out char for reference\n",
    "#             cv2.imshow(\"imgROIResized\", imgROIResized)      # show resized image for reference\n",
    "            \n",
    "#             cv2.imshow(\"training_numbers.png\", imgTrainingNumbers)      # show training numbers image, this will now have red rectangles drawn on it\n",
    "\n",
    "#             intChar = cv2.waitKey(0)                     # get key press\n",
    "\n",
    "#             if intChar == 27:                   # if esc key was pressed\n",
    "#                 sys.exit()                      # exit program\n",
    "#             elif intChar in intValidChars:      # else if the char is in the list of chars we are looking for . . .\n",
    "\n",
    "#                 intClassifications.append(intChar)        # append classification char to integer list of chars (we will convert to float later before writing to file)\n",
    "#                 #Là file chứa label của tất cả các ảnh mẫu, tổng cộng có 32 x 5 = 160 mẫu.\n",
    "#                 npaFlattenedImage = imgROIResized.reshape((1, RESIZED_IMAGE_WIDTH * RESIZED_IMAGE_HEIGHT))  # flatten image to 1d numpy array so we can write to file later\n",
    "                \n",
    "#                 npaFlattenedImages = np.append(npaFlattenedImages, npaFlattenedImage, 0)                    # add current flattened impage numpy array to list of flattened image numpy arrays\n",
    "                \n",
    "#             # end if\n",
    "#         # end if\n",
    "#     # end for\n",
    "\n",
    "#     fltClassifications = np.array(intClassifications, np.float32)                   # convert classifications list of ints to numpy array of floats\n",
    "    \n",
    "#     npaClassifications = fltClassifications.reshape((fltClassifications.size, 1))   # flatten numpy array of floats to 1d so we can write to file later\n",
    "\n",
    "#     print (\"\\n\\ntraining complete !!\\n\")\n",
    "\n",
    "#     np.savetxt(\"classifications.txt\", npaClassifications)           # write flattened images to file\n",
    "#     np.savetxt(\"flattened_images.txt\", npaFlattenedImages)          #\n",
    "\n",
    "#     cv2.destroyAllWindows()             # remove windows from memory\n",
    "\n",
    "#     return\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53883c14-49d9-40b8-9527-8072b6a9dcd5",
   "metadata": {},
   "source": [
    "# 2. Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70c0e3c4-f990-43ad-a900-9c134d0045d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84360607-ab66-4112-9318-9b4dcd3dc07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module level variables\n",
    "GAUSSIAN_SMOOTH_FILTER_SIZE = (5, 5) #kích cỡ càng to thì càng mờ\n",
    "ADAPTIVE_THRESH_BLOCK_SIZE = 19 \n",
    "ADAPTIVE_THRESH_WEIGHT = 9  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae63d382-9b5a-4db3-9bc9-91f29f5f5e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(imgOriginal):\n",
    "\n",
    "    imgGrayscale = extractValue(imgOriginal)\n",
    "    # imgGrayscale = cv2.cvtColor(imgOriginal,cv2.COLOR_BGR2GRAY) nên dùng hệ màu HSV\n",
    "    # Trả về giá trị cường độ sáng ==> ảnh gray\n",
    "    imgMaxContrastGrayscale = maximizeContrast(imgGrayscale) #để làm nổi bật biển số hơn, dễ tách khỏi nền\n",
    "    #cv2.imwrite(\"imgGrayscalePlusTopHatMinusBlackHat.jpg\",imgMaxContrastGrayscale)\n",
    "    height, width = imgGrayscale.shape\n",
    "\n",
    "    imgBlurred = np.zeros((height, width, 1), np.uint8)\n",
    "    imgBlurred = cv2.GaussianBlur(imgMaxContrastGrayscale, GAUSSIAN_SMOOTH_FILTER_SIZE, 0)\n",
    "    #cv2.imwrite(\"gauss.jpg\",imgBlurred)\n",
    "    #Làm mịn ảnh bằng bộ lọc Gauss 5x5, sigma = 0\n",
    "\n",
    "    imgThresh = cv2.adaptiveThreshold(imgBlurred, 255.0, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, ADAPTIVE_THRESH_BLOCK_SIZE, ADAPTIVE_THRESH_WEIGHT)\n",
    "\n",
    "    #Tạo ảnh nhị phân\n",
    "    return imgGrayscale, imgThresh\n",
    "#Trả về ảnh xám và ảnh nhị phân"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a005efda-56be-433b-ada2-c90a37a50918",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractValue(imgOriginal):\n",
    "    height, width, numChannels = imgOriginal.shape\n",
    "    imgHSV = np.zeros((height, width, 3), np.uint8)\n",
    "    imgHSV = cv2.cvtColor(imgOriginal, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    imgHue, imgSaturation, imgValue = cv2.split(imgHSV)\n",
    "    \n",
    "    #màu sắc, độ bão hòa, giá trị cường độ sáng\n",
    "    #Không chọn màu RBG vì vd ảnh màu đỏ sẽ còn lẫn các màu khác nữa nên khó xđ ra \"một màu\" \n",
    "    return imgValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e5eb46f-5787-4e36-b3c9-51a7c5e8a1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximizeContrast(imgGrayscale):\n",
    "    #Làm cho độ tương phản lớn nhất \n",
    "    height, width = imgGrayscale.shape\n",
    "    \n",
    "    imgTopHat = np.zeros((height, width, 1), np.uint8)\n",
    "    imgBlackHat = np.zeros((height, width, 1), np.uint8)\n",
    "    structuringElement = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3)) #tạo bộ lọc kernel\n",
    "    \n",
    "    imgTopHat = cv2.morphologyEx(imgGrayscale, cv2.MORPH_TOPHAT, structuringElement, iterations = 10) #nổi bật chi tiết sáng trong nền tối\n",
    "    #cv2.imwrite(\"tophat.jpg\",imgTopHat)\n",
    "    imgBlackHat = cv2.morphologyEx(imgGrayscale, cv2.MORPH_BLACKHAT, structuringElement, iterations = 10) #Nổi bật chi tiết tối trong nền sáng\n",
    "    #cv2.imwrite(\"blackhat.jpg\",imgBlackHat)\n",
    "    imgGrayscalePlusTopHat = cv2.add(imgGrayscale, imgTopHat) \n",
    "    imgGrayscalePlusTopHatMinusBlackHat = cv2.subtract(imgGrayscalePlusTopHat, imgBlackHat)\n",
    "\n",
    "    #cv2.imshow(\"imgGrayscalePlusTopHatMinusBlackHat\",imgGrayscalePlusTopHatMinusBlackHat)\n",
    "    #Kết quả cuối là ảnh đã tăng độ tương phản \n",
    "    return imgGrayscalePlusTopHatMinusBlackHat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f073918d-ef6a-46fe-9421-f036d37b830d",
   "metadata": {},
   "source": [
    "# 3. Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f757637a-713b-45d0-a797-db2d98bef6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "ADAPTIVE_THRESH_BLOCK_SIZE = 19\n",
    "ADAPTIVE_THRESH_WEIGHT = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40422626-b906-4958-af7d-15a6d65ca04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "\n",
    "Min_char = 0.01\n",
    "Max_char = 0.09\n",
    "\n",
    "RESIZED_IMAGE_WIDTH = 20\n",
    "RESIZED_IMAGE_HEIGHT = 30\n",
    "\n",
    "img = cv2.imread(\"image/2.jpg\")\n",
    "img = cv2.resize(img, dsize=(1920, 1080))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd8783e8-d3cb-4728-94f3-4080e2240f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# increasing the contrast \n",
    "# img2 = cv2.imread(\"1.jpg\")\n",
    "# imgGrayscaleplate2, _ = Preprocess.preprocess(img)\n",
    "# imgThreshplate2 = cv2.adaptiveThreshold(imgGrayscaleplate2, 250, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, ADAPTIVE_THRESH_BLOCK_SIZE ,ADAPTIVE_THRESH_WEIGHT )\n",
    "# cv2.imshow(\"imgThreshplate2\",imgThreshplate2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2196a15d-1ca6-48b8-8d93-84dc2b6571a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload KNN model\n",
    "npaClassifications = np.loadtxt(\"classifications.txt\", np.float32)\n",
    "npaFlattenedImages = np.loadtxt(\"flattened_images.txt\", np.float32)\n",
    "npaClassifications = npaClassifications.reshape(\n",
    "    (npaClassifications.size, 1))  # reshape numpy array to 1d, necessary to pass to call to train\n",
    "kNearest = cv2.ml.KNearest_create()  # instantiate KNN object\n",
    "kNearest.train(npaFlattenedImages, cv2.ml.ROW_SAMPLE, npaClassifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14316c83-afbf-49e4-bff2-a19a75ccfbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Preprocessing\n",
    "imgGrayscaleplate, imgThreshplate = preprocess(img)\n",
    "canny_image = cv2.Canny(imgThreshplate, 250, 255)  # Canny Edge\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "dilated_image = cv2.dilate(canny_image, kernel, iterations=1)  # Dilation\n",
    "# cv2.imshow(\"dilated_image\",dilated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789cc7dc-bd87-4d80-a7b0-c852cda9946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')  # Tắt hiển thị trục\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbbd303-287b-490d-9242-78675232937c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " License Plate 1 is: 49 - 01989\n",
      "\n",
      "\n",
      " License Plate 2 is: 49 - 01989\n",
      "\n",
      "\n",
      " License Plate 3 is: 49 - 01989\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Draw contour and filter out the license plate\n",
    "contours, hierarchy = cv2.findContours(dilated_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]  # Lấy 10 contours có diện tích lớn nhất\n",
    "# cv2.drawContours(img, contours, -1, (255, 0, 255), 3) # Vẽ tất cả các ctour trong hình lớn\n",
    "\n",
    "screenCnt = []\n",
    "for c in contours:\n",
    "    peri = cv2.arcLength(c, True)  # Tính chu vi\n",
    "    approx = cv2.approxPolyDP(c, 0.06 * peri, True)  # làm xấp xỉ đa giác, chỉ giữ contour có 4 cạnh\n",
    "    [x, y, w, h] = cv2.boundingRect(approx.copy())\n",
    "    ratio = w / h\n",
    "    # cv2.putText(img, str(len(approx.copy())), (x,y),cv2.FONT_HERSHEY_DUPLEX, 2, (0, 255, 0), 3)\n",
    "    # cv2.putText(img, str(ratio), (x,y),cv2.FONT_HERSHEY_DUPLEX, 2, (0, 255, 0), 3)\n",
    "    if (len(approx) == 4):\n",
    "        screenCnt.append(approx)\n",
    "\n",
    "        cv2.putText(img, str(len(approx.copy())), (x, y), cv2.FONT_HERSHEY_DUPLEX, 2, (0, 255, 0), 3)\n",
    "\n",
    "if screenCnt is None:\n",
    "    detected = 0\n",
    "    print(\"No plate detected\")\n",
    "else:\n",
    "    detected = 1\n",
    "\n",
    "if detected == 1:\n",
    "\n",
    "    for screenCnt in screenCnt:\n",
    "        cv2.drawContours(img, [screenCnt], -1, (0, 255, 0), 3)  # Khoanh vùng biển số xe\n",
    "\n",
    "        # Find the angle of the license plate\n",
    "        (x1, y1) = screenCnt[0, 0]\n",
    "        (x2, y2) = screenCnt[1, 0]\n",
    "        (x3, y3) = screenCnt[2, 0]\n",
    "        (x4, y4) = screenCnt[3, 0]\n",
    "        array = [[x1, y1], [x2, y2], [x3, y3], [x4, y4]]\n",
    "        sorted_array = array.sort(reverse=True, key=lambda x: x[1])\n",
    "        (x1, y1) = array[0]\n",
    "        (x2, y2) = array[1]\n",
    "        doi = abs(y1 - y2)\n",
    "        ke = abs(x1 - x2)\n",
    "        angle = math.atan(doi / ke) * (180.0 / math.pi)\n",
    "\n",
    "        # Crop out the license plate and align it to the right angle\n",
    "\n",
    "        mask = np.zeros(imgGrayscaleplate.shape, np.uint8)\n",
    "        new_image = cv2.drawContours(mask, [screenCnt], 0, 255, -1, )\n",
    "        # cv2.imshow(\"new_image\",new_image)\n",
    "\n",
    "        # Cropping\n",
    "        (x, y) = np.where(mask == 255)\n",
    "        (topx, topy) = (np.min(x), np.min(y))\n",
    "        (bottomx, bottomy) = (np.max(x), np.max(y))\n",
    "\n",
    "        roi = img[topx:bottomx, topy:bottomy]\n",
    "        imgThresh = imgThreshplate[topx:bottomx, topy:bottomy]\n",
    "        ptPlateCenter = (bottomx - topx) / 2, (bottomy - topy) / 2\n",
    "\n",
    "        if x1 < x2:\n",
    "            rotationMatrix = cv2.getRotationMatrix2D(ptPlateCenter, -angle, 1.0)\n",
    "        else:\n",
    "            rotationMatrix = cv2.getRotationMatrix2D(ptPlateCenter, angle, 1.0)\n",
    "\n",
    "        roi = cv2.warpAffine(roi, rotationMatrix, (bottomy - topy, bottomx - topx))\n",
    "        imgThresh = cv2.warpAffine(imgThresh, rotationMatrix, (bottomy - topy, bottomx - topx))\n",
    "        roi = cv2.resize(roi, (0, 0), fx=3, fy=3)\n",
    "        imgThresh = cv2.resize(imgThresh, (0, 0), fx=3, fy=3)\n",
    "\n",
    "\n",
    "        # Prepocessing and Character segmentation\n",
    "        kerel3 = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "        thre_mor = cv2.morphologyEx(imgThresh, cv2.MORPH_DILATE, kerel3)\n",
    "        cont, hier = cv2.findContours(thre_mor, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        cv2.imshow(str(n + 20), thre_mor)\n",
    "        cv2.drawContours(roi, cont, -1, (100, 255, 255), 2)  # Vẽ contour các kí tự trong biển số\n",
    "\n",
    "        # Filter out characters\n",
    "        char_x_ind = {}\n",
    "        char_x = []\n",
    "        height, width, _ = roi.shape\n",
    "        roiarea = height * width\n",
    "\n",
    "        for ind, cnt in enumerate(cont):\n",
    "            (x, y, w, h) = cv2.boundingRect(cont[ind])\n",
    "            ratiochar = w / h\n",
    "            char_area = w * h\n",
    "            # cv2.putText(roi, str(char_area), (x, y+20),cv2.FONT_HERSHEY_DUPLEX, 2, (255, 255, 0), 2)\n",
    "            # cv2.putText(roi, str(ratiochar), (x, y+20),cv2.FONT_HERSHEY_DUPLEX, 2, (255, 255, 0), 2)\n",
    "\n",
    "            if (Min_char * roiarea < char_area < Max_char * roiarea) and (0.25 < ratiochar < 0.7):\n",
    "                if x in char_x:  # Sử dụng để dù cho trùng x vẫn vẽ được\n",
    "                    x = x + 1\n",
    "                char_x.append(x)\n",
    "                char_x_ind[x] = ind\n",
    "\n",
    "                # cv2.putText(roi, str(char_area), (x, y+20),cv2.FONT_HERSHEY_DUPLEX, 2, (255, 255, 0), 2)\n",
    "\n",
    "        #Character recognition\n",
    "\n",
    "        char_x = sorted(char_x)\n",
    "        strFinalString = \"\"\n",
    "        first_line = \"\"\n",
    "        second_line = \"\"\n",
    "\n",
    "        for i in char_x:\n",
    "            (x, y, w, h) = cv2.boundingRect(cont[char_x_ind[i]])\n",
    "            cv2.rectangle(roi, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            imgROI = thre_mor[y:y + h, x:x + w]  # Crop the characters\n",
    "\n",
    "            imgROIResized = cv2.resize(imgROI, (RESIZED_IMAGE_WIDTH, RESIZED_IMAGE_HEIGHT))  # resize image\n",
    "            npaROIResized = imgROIResized.reshape(\n",
    "                (1, RESIZED_IMAGE_WIDTH * RESIZED_IMAGE_HEIGHT))\n",
    "\n",
    "            npaROIResized = np.float32(npaROIResized)\n",
    "            _, npaResults, neigh_resp, dists = kNearest.findNearest(npaROIResized,k=3)  # call KNN function find_nearest;\n",
    "            strCurrentChar = str(chr(int(npaResults[0][0])))  # ASCII of characters\n",
    "            cv2.putText(roi, strCurrentChar, (x, y + 50), cv2.FONT_HERSHEY_DUPLEX, 2, (255, 255, 0), 3)\n",
    "\n",
    "            if (y < height / 3):  # decide 1 or 2-line license plate\n",
    "                first_line = first_line + strCurrentChar\n",
    "            else:\n",
    "                second_line = second_line + strCurrentChar\n",
    "\n",
    "        print(\"\\n License Plate \" + str(n) + \" is: \" + first_line + \" - \" + second_line + \"\\n\")\n",
    "        roi = cv2.resize(roi, None, fx=0.75, fy=0.75)\n",
    "        cv2.imshow(str(n), cv2.cvtColor(roi, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # cv2.putText(img, first_line + \"-\" + second_line ,(topy ,topx),cv2.FONT_HERSHEY_DUPLEX, 2, (0, 255, 255), 2)\n",
    "        n = n + 1\n",
    "\n",
    "img = cv2.resize(img, None, fx=0.5, fy=0.5)\n",
    "#cv2.imshow('License plate', img)\n",
    "\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1518d23-7845-44f0-a593-671bdbb95c80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f573ecfe-4714-4372-83c5-97dea25fe20f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb472ff-369d-4746-9f45-0ba2771a2787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b908c9-507e-4ecc-a133-e9b16501668e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7e2376-d939-45e5-9b69-febf9c2451c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "07a6b268f2658f7bb46e42b9678d82efd26886f1589feca769873f2e2e223d24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
